{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLlaauc5hM8qhYJ7BT2SMu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdithGH762/Fundamentals-of-ML/blob/main/Unbalanced_Data_SMOTE_LAB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EERwv1G3XlwK",
        "outputId": "f238fad6-f9b2-479d-c7a4-9fb7fff17562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.1)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<0.2,>=0.1.5 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (0.1.5)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n",
            "First 5 rows:\n",
            "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
            "0  LP001002   Male      No          0      Graduate            No   \n",
            "1  LP001003   Male     Yes          1      Graduate            No   \n",
            "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
            "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
            "4  LP001008   Male      No          0      Graduate            No   \n",
            "\n",
            "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
            "0             5849                0.0         NaN             360.0   \n",
            "1             4583             1508.0       128.0             360.0   \n",
            "2             3000                0.0        66.0             360.0   \n",
            "3             2583             2358.0       120.0             360.0   \n",
            "4             6000                0.0       141.0             360.0   \n",
            "\n",
            "   Credit_History Property_Area Loan_Status  \n",
            "0             1.0         Urban           Y  \n",
            "1             1.0         Rural           N  \n",
            "2             1.0         Urban           Y  \n",
            "3             1.0         Urban           Y  \n",
            "4             1.0         Urban           Y  \n",
            "\n",
            "Original Class Distribution:\n",
            "Loan_Status\n",
            "1    422\n",
            "0    192\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Majority Class: 1\n",
            "Minority Class: 0\n",
            "\n",
            "=== Baseline Model (Imbalanced Data) ===\n",
            "Accuracy: 0.8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.59      0.65        58\n",
            "           1       0.83      0.90      0.86       127\n",
            "\n",
            "    accuracy                           0.80       185\n",
            "   macro avg       0.77      0.74      0.75       185\n",
            "weighted avg       0.79      0.80      0.79       185\n",
            "\n",
            "\n",
            "=== Manual Duplication Oversampling ===\n",
            "Accuracy: 0.8216216216216217\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.64      0.69        58\n",
            "           1       0.85      0.91      0.87       127\n",
            "\n",
            "    accuracy                           0.82       185\n",
            "   macro avg       0.80      0.77      0.78       185\n",
            "weighted avg       0.82      0.82      0.82       185\n",
            "\n",
            "\n",
            "After SMOTE Class Distribution:\n",
            "Loan_Status\n",
            "1    295\n",
            "0    295\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== SMOTE Oversampling ===\n",
            "Accuracy: 0.7945945945945946\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.62      0.65        58\n",
            "           1       0.83      0.87      0.85       127\n",
            "\n",
            "    accuracy                           0.79       185\n",
            "   macro avg       0.76      0.75      0.75       185\n",
            "weighted avg       0.79      0.79      0.79       185\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# STEP 1: Install Required Library\n",
        "# ==========================================\n",
        "!pip install imbalanced-learn\n",
        "\n",
        "# ==========================================\n",
        "# STEP 2: Import Libraries\n",
        "# ==========================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ==========================================\n",
        "# STEP 3: Load Dataset\n",
        "# ==========================================\n",
        "df = pd.read_csv('/content/Loan.csv')   # Make sure Loan.csv is uploaded\n",
        "print(\"First 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# ==========================================\n",
        "# STEP 4: Drop Unnecessary Columns\n",
        "# ==========================================\n",
        "if 'Loan_ID' in df.columns:\n",
        "    df.drop('Loan_ID', axis=1, inplace=True)\n",
        "\n",
        "# ==========================================\n",
        "# STEP 5: Encode Categorical Variables\n",
        "# ==========================================\n",
        "le = LabelEncoder()\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col] = le.fit_transform(df[col].astype(str))\n",
        "\n",
        "# ==========================================\n",
        "# STEP 6: Separate Features & Target\n",
        "# ==========================================\n",
        "X = df.drop('Loan_Status', axis=1)\n",
        "y = df['Loan_Status']\n",
        "\n",
        "# ==========================================\n",
        "# STEP 7: Handle Missing Values (Important for SMOTE)\n",
        "# ==========================================\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = imputer.fit_transform(X)\n",
        "X = pd.DataFrame(X, columns=df.drop('Loan_Status', axis=1).columns)\n",
        "\n",
        "# ==========================================\n",
        "# STEP 8: Check Original Class Distribution\n",
        "# ==========================================\n",
        "print(\"\\nOriginal Class Distribution:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "majority_class = y.value_counts().idxmax()\n",
        "minority_class = y.value_counts().idxmin()\n",
        "\n",
        "print(\"\\nMajority Class:\", majority_class)\n",
        "print(\"Minority Class:\", minority_class)\n",
        "\n",
        "# ==========================================\n",
        "# STEP 9: Train-Test Split\n",
        "# ==========================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# STEP 10: Baseline Model (Imbalanced Data)\n",
        "# ==========================================\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"\\n=== Baseline Model (Imbalanced Data) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# ==========================================\n",
        "# STEP 11: Manual Oversampling (Duplicate Minority)\n",
        "# ==========================================\n",
        "train_data = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "majority_data = train_data[train_data['Loan_Status'] == majority_class]\n",
        "minority_data = train_data[train_data['Loan_Status'] == minority_class]\n",
        "\n",
        "minority_upsampled = minority_data.sample(\n",
        "    n=len(majority_data),\n",
        "    replace=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "balanced_data = pd.concat([majority_data, minority_upsampled])\n",
        "\n",
        "X_train_dup = balanced_data.drop('Loan_Status', axis=1)\n",
        "y_train_dup = balanced_data['Loan_Status']\n",
        "\n",
        "model_dup = RandomForestClassifier(random_state=42)\n",
        "model_dup.fit(X_train_dup, y_train_dup)\n",
        "y_pred_dup = model_dup.predict(X_test)\n",
        "\n",
        "print(\"\\n=== Manual Duplication Oversampling ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dup))\n",
        "print(classification_report(y_test, y_pred_dup))\n",
        "\n",
        "# ==========================================\n",
        "# STEP 12: SMOTE Oversampling\n",
        "# ==========================================\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nAfter SMOTE Class Distribution:\")\n",
        "print(pd.Series(y_train_smote).value_counts())\n",
        "\n",
        "model_smote = RandomForestClassifier(random_state=42)\n",
        "model_smote.fit(X_train_smote, y_train_smote)\n",
        "y_pred_smote = model_smote.predict(X_test)\n",
        "\n",
        "print(\"\\n=== SMOTE Oversampling ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_smote))\n",
        "print(classification_report(y_test, y_pred_smote))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "648Y_MLLYVMr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}